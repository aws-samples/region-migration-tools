# main.py
import json
import logging
import sys
import os
from ctypes.wintypes import tagRECT
from typing import Dict, List

from strands import Agent, tool
from strands.tools.mcp import MCPClient
from mcp import stdio_client, StdioServerParameters
from utils.config import ExpansionPlaningInputs
from utils.config import Config, Constants
from utils.prompts import WaypointPrompts
from agents import cfn_explorer, cloudtrail_explorer, analysis_writer, waypoint_explorer, multi_region_expansion_planner, planning_report_generator, report_writer, pricing_explorer, tech_analysis_writer
from strands_tools import use_aws, file_read, file_write, python_repl, editor, shell

# Add parent directory to path for imports
SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))
sys.path.append(os.path.dirname(SCRIPT_DIR))

try:

    STRANDS_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Strands not available: {e}")
    STRANDS_AVAILABLE = False
    # Define dummy decorator for when strands is not available
    def tool(func):
        return func

# Configure logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger('botocore').setLevel(logging.WARNING)


def orchestrate_analysis(profile: str, source_region: str, target_regions: List, lookback_days: int = 7) -> Dict:
    """
    Orchestrates the dependency analysis workflow.
    """
    try:
        logger.info(f"Starting analysis..")

        # Set required configurations
        Constants.set_tool_configurations()

        model = Config.construct_bedrock_model(
            temperature=Constants.ORCHESTRATOR_TEMPERATURE
        )

        common_tools = [use_aws, file_read, file_write, editor, shell]
        agents = [cfn_explorer, cloudtrail_explorer, waypoint_explorer, analysis_writer, multi_region_expansion_planner, planning_report_generator, report_writer, pricing_explorer, tech_analysis_writer]

        orchestrator = Agent(
            model=model,
            system_prompt=WaypointPrompts.SYSTEM_PROMPT,
            tools=common_tools+agents
        )

        analysis_request = f"""Analyze Resources for Regional expansion for:
                Account Profile : {profile}
                Source Region: {source_region}
                Target Region: {target_regions}

                1. First use cfn_explorer tool and collect all cloudformation resources deployed to account in {source_region} region and AWS profile {profile} .
                2. Pass the output from cfn_explorer to analysis_writer tool.
                3. Next collect all services (event source) and api actions (event name) from CloudTrail logs of the account in {source_region} region for the past {lookback_days} days as lookback data using the tool cloudtrail_explorer and using the AWS profile {profile}.
                4. Pass the output from cloudtrail_explorer to analysis_writer tool.
                5. Use waypoint_explorer tool to identify avilability gaps in target region. Pass the output from cfn_explorer and cloudtrail_explorer to waypoint_explorer for each region in target regions {target_regions} and collect the output. 
                6. Pass the output from waypoint_explorer tool to analysis_writer tool for each of the regions in {target_regions} regions to save the identified gaps or reports for each of the target region.
                7. Read all the analysis results from the files in `./analysis_results` directory and create a technical analysis document and save the output as `technical_analysis.md` in the same directory.
                8. Then use the multi_region_expansion_planner tool to get detailed planning analysis to deploy workloads into target regions {target_regions} from source region {source_region} using analysis generated by all previous agents like cfn_explorer, cloudtrail_explorer and waypoint_explorer and which save the output as `multi_region_expansion_planning_report.md` to `analysis_results` drive.
                9. Using planning_report_generator tool for {source_region} and {target_regions} tool based on all the input you received from other agents generate complete expansion planning report which save the report to `expansion_planning_report.md` file in .
                10. See the `analysis_results` folder for exiting outputs. Skip over any agents where output exists and instead read the json output files and proceed as if you were resuming a paused work.
                11. Ensure you have `technical_analysis.md`, `multi_region_expansion_planning_report.md`, `expansion_planning_report.md` files before ending the workflow.
                
                See the `analysis_results` folder for exiting outputs. Skip over any agents where output exists and instead read the json output files and proceed as if you were resuming a paused work.
                """

        response = orchestrator(analysis_request)

        # Get response content
        response_content = str(response.content if hasattr(response, 'content') else response)
        # Clean up the response to extract markdown
        # Remove any JSON formatting and get the raw markdown
        try:
            # Try to find markdown content within JSON if present
            if response_content.strip().startswith('{'):
                data = json.loads(response_content)
                if 'raw_response' in data:
                    markdown_content = data['raw_response']
                else:
                    markdown_content = response_content
            else:
                markdown_content = response_content

            # Ensure it starts with a proper header if not present
            if not markdown_content.strip().startswith('#'):
                markdown_content = f"# Analysis Results for {profile}\n\n## Source Region: {source_region}\n\n{markdown_content}"

            return {
                "status": "success",
                "profile": profile,
                "source_region": source_region,
                "recommendation": markdown_content  # Use same key as recommender endpoint
            }

            
        except Exception as e:
            return {"status": "failure", "message": e}
    except Exception as e:
        return {"status": "failure", "message": e}




def run_cli():
    profile = ExpansionPlaningInputs.PROFILE_NAME
    source_region = ExpansionPlaningInputs.SOURCE_REGION
    target_regions = ExpansionPlaningInputs.TARGET_REGIONS
    lookback_days = ExpansionPlaningInputs.CTRAIL_LOOKBACK_DAYS

    result = orchestrate_analysis(profile=profile, source_region=source_region, target_regions=target_regions, lookback_days = lookback_days)
    print(result)

    """if result["status"] == "success":
        sys.exit(0)
    else:
        sys.exit(1)"""


if __name__ == "__main__":
    run_cli()